{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model generator main file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import unidecode\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection     import GridSearchCV\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints           import maxnorm\n",
    "from keras                       import regularizers\n",
    "from keras                       import Input, Model, Sequential\n",
    "from keras.layers                import Flatten, TimeDistributed, CuDNNGRU, CuDNNLSTM, Bidirectional, Activation, TimeDistributed, Dense, RepeatVector, Embedding, Dropout, BatchNormalization\n",
    "from keras.layers.recurrent      import LSTM, GRU, SimpleRNN\n",
    "from keras.utils                 import np_utils\n",
    "from keras.callbacks             import EarlyStopping, TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data and make folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Check sizes =====\n",
      "joint_angle_data shape is: \n",
      "(32501, 19)\n",
      "power_data shape is: \n",
      "(32501, 1)\n",
      "First value needs to be equal!\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "temp_path = data_path + '/temp'\n",
    "backup_path = data_path + '/backup'\n",
    "weights_path = data_path + '/weights'\n",
    "train_history = data_path + '/train_history'\n",
    "\n",
    "if not os.path.isdir(data_path):\n",
    "    os.mkdir(data_path)\n",
    "if not os.path.isdir(temp_path):\n",
    "    os.mkdir(temp_path)\n",
    "if not os.path.isdir(backup_path):\n",
    "    os.mkdir(backup_path)\n",
    "if not os.path.isdir(weights_path):\n",
    "    os.mkdir(weights_path)\n",
    "if not os.path.isdir(train_history):\n",
    "    os.mkdir(train_history)\n",
    "\n",
    "#joint_angle_data.pickle\n",
    "with open(data_path + '/augmented_input.pickle', 'rb') as file:\n",
    "    joint_angle_data = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "#power_data.pickle\n",
    "with open(data_path + '/power_data.pickle', 'rb') as file:\n",
    "    power_data = pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "print('===== Check sizes =====')\n",
    "print('joint_angle_data shape is: ')\n",
    "print(joint_angle_data.shape)\n",
    "print('power_data shape is: ')\n",
    "print(power_data.shape)\n",
    "print('First value needs to be equal!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModelToBasicLSTM(self, multiple=False):\n",
    "    n_timesteps, n_features, n_outputs = self.X_train.shape[1], self.X_train.shape[2], self.Y_train.shape[-1]\n",
    "    # define model\n",
    "    self.model = Sequential()\n",
    "    self.model.add(Bidirectional(CuDNNLSTM(128, return_sequences = True, kernel_initializer = 'random_uniform', bias_initializer = 'zero', input_shape = (n_timesteps, n_features))))\n",
    "    self.model.add(Dropout(0.2))\n",
    "    self.model.add(Bidirectional(CuDNNLSTM(128, return_sequences = True, kernel_initializer = 'random_uniform', bias_initializer = 'zero')))\n",
    "    self.model.add(Dropout(0.2))\n",
    "    self.model.add(Bidirectional(CuDNNLSTM(128, return_sequences = True, kernel_initializer = 'random_uniform', bias_initializer = 'zero')))\n",
    "    self.model.add(Dropout(0.2))\n",
    "    self.model.add(Bidirectional(CuDNNLSTM(128, return_sequences = multiple, kernel_initializer = 'random_uniform', bias_initializer = 'zero')))\n",
    "    self.model.add(Dropout(0.2))\n",
    "    if multiple:\n",
    "        self.model.add(TimeDistributed(Dense(128, activation='relu', kernel_initializer = 'random_uniform', bias_initializer = 'zero')))\n",
    "        self.model.add(TimeDistributed(Dense(n_outputs)))\n",
    "    else:\n",
    "        self.model.add(Dense(128, activation='relu', kernel_initializer = 'random_uniform', bias_initializer = 'zero'))\n",
    "        self.model.add(Dense(n_outputs))\n",
    "    self.model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=[mean_square_error])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModelToGridSearch(self, multiple=False, layer_type=CuDNNLSTM, hidden_units_RNN=128, hidden_units_dense=64, num_mid_layers = 3, optimizer='adam', init_mode='random_uniform', activation='relu', dropout_rate=0.2, num_dense_layers=1):\n",
    "    n_timesteps, n_features, n_outputs = self.X_train.shape[1], self.X_train.shape[2], self.Y_train.shape[-1]\n",
    "    # define model\n",
    "    self.model = Sequential()\n",
    "    self.model.add(Bidirectional(layer_type(hidden_units_RNN, return_sequences = True, kernel_initializer = init_mode, bias_initializer = 'zero', input_shape = (n_timesteps, n_features))))\n",
    "    for n in range(num_mid_layers):\n",
    "        self.model.add(Bidirectional(layer_type(hidden_units_RNN, return_sequences = True, kernel_initializer = init_mode, bias_initializer = 'zero')))\n",
    "        self.model.add(Dropout(dropout_rate))\n",
    "        \n",
    "    self.model.add(Bidirectional(layer_type(hidden_units_RNN, return_sequences = multiple, kernel_initializer = init_mode, bias_initializer = 'zero')))\n",
    "    self.model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    if multiple:\n",
    "        for n in range(num_dense_layers):\n",
    "            self.model.add(TimeDistributed(Dense(hidden_units_dense, activation=activation, kernel_initializer = 'random_uniform', bias_initializer = 'zero'))) #, kernel_constraint=maxnorm(weight_constraint)\n",
    "    \n",
    "        self.model.add(TimeDistributed(Dense(n_outputs)))\n",
    "    else:\n",
    "        for n in range(num_dense_layers):\n",
    "            self.model.add(Dense(hidden_units_dense, activation=activation, kernel_initializer = 'random_uniform', bias_initializer = 'zero')) #, kernel_constraint=maxnorm(weight_constraint)\n",
    "    \n",
    "        self.model.add(Dense(n_outputs))\n",
    "        \n",
    "    self.model.compile(loss='mean_absolute_percentage_error', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModelToFFNN(self):\n",
    "    n_timesteps, n_features, n_outputs = self.X_train.shape[1], self.X_train.shape[2], self.Y_train.shape[1]\n",
    "\n",
    "    inputs = Input(shape=(n_timesteps,n_features))\n",
    "    x = Dense(128, activation='relu')(inputs)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    prediction = Dense(n_outputs, activation='relu')(x)\n",
    "    \n",
    "    self.model = Model(inputs, prediction)\n",
    "    self.model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=[\"mean_square_error\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModelToFinalModel(self, multiple=False):\n",
    "    n_timesteps, n_features, n_outputs = self.X_train.shape[1], self.X_train.shape[2], self.Y_train.shape[-1]\n",
    "    # define model\n",
    "    self.model = Sequential()\n",
    "    self.model.add(Bidirectional(CuDNNLSTM(128, return_sequences = True, kernel_initializer = 'random_uniform', bias_initializer = 'zero', input_shape = (n_timesteps, n_features))))\n",
    "    self.model.add(Dropout(0.2))\n",
    "    self.model.add(Bidirectional(CuDNNLSTM(128, return_sequences = True, kernel_initializer = 'random_uniform', bias_initializer = 'zero')))\n",
    "    self.model.add(Dropout(0.2))\n",
    "    self.model.add(Bidirectional(CuDNNLSTM(128, return_sequences = True, kernel_initializer = 'random_uniform', bias_initializer = 'zero')))\n",
    "    self.model.add(Dropout(0.2))\n",
    "    self.model.add(Bidirectional(CuDNNLSTM(128, return_sequences = multiple, kernel_initializer = 'random_uniform', bias_initializer = 'zero')))\n",
    "    self.model.add(Dropout(0.2))\n",
    "    if multiple:\n",
    "        self.model.add(TimeDistributed(Dense(128, activation='relu', kernel_initializer = 'random_uniform', bias_initializer = 'zero')))\n",
    "        self.model.add(TimeDistributed(Dense(n_outputs)))\n",
    "    else:\n",
    "        self.model.add(Dense(128, activation='relu', kernel_initializer = 'random_uniform', bias_initializer = 'zero'))\n",
    "        self.model.add(Dense(n_outputs))\n",
    "    self.model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=[mean_square_error])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(dataX, dataY, n_input, n_output, multiple=False):\n",
    "    #Output: [batchs, n_timesteps, n_features]\n",
    "    df_X = pd.DataFrame(dataX)\n",
    "    df_Y = pd.DataFrame(dataY)\n",
    "    X = np.ndarray((df_X.shape[0]-n_input, n_input, df_X.shape[1]) )\n",
    "    if multiple:\n",
    "        Y = np.ndarray((df_Y.shape[0]-n_input, n_input, n_output))\n",
    "    else:\n",
    "        Y = np.ndarray((df_Y.shape[0]-n_input, n_output))\n",
    "\n",
    "    for n in range(0,df_X.shape[0]-n_input-1,1):\n",
    "        for m in range(n_input-1,-1, -1):\n",
    "            X[n,m,:] = df_X.loc[n+m:n+m,:]\n",
    "    if multiple:\n",
    "        for n in range(0,df_Y.shape[0]-n_input-1,1):\n",
    "            for m in range(n_input-1,-1, -1):\n",
    "                Y[n,m,:] = df_Y.loc[n+m:n+m,:]\n",
    "    else:\n",
    "        for n in range(0,df_Y.shape[0]-n_input-1,1):\n",
    "            for m in range(n_output-1,-1, -1):\n",
    "                Y[n,:] = df_Y.loc[n+m:n+m,:]\n",
    "            \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setUpData(self, seq_length, dataX, dataY, n_test_ratio, multiple=False):\n",
    "\n",
    "    self.X_train = []\n",
    "    self.Y_train = []\n",
    "    self.X_test = []\n",
    "    self.Y_test = []\n",
    "    self.seq_length = seq_length\n",
    "    \n",
    "    X, Y = series_to_supervised(dataX, dataY, multiple=multiple, n_input=seq_length, n_output=dataY.shape[1])\n",
    "    \n",
    "    self.X_train = X[:int(len(X)*(1-n_test_ratio)), :, :]\n",
    "    self.Y_train = Y[:int(len(Y)*(1-n_test_ratio)), :]\n",
    "    self.X_test = X[int(len(X)*(1-n_test_ratio)):, :, :]\n",
    "    self.Y_test = Y[int(len(Y)*(1-n_test_ratio)):, :]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(self, name):\n",
    "    # File path for model\n",
    "    filepath = weights_path + \"/weights-\" + name + \"-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    # Callbacks functions\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "    tb = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32)\n",
    "    mc = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\n",
    "    \n",
    "    # Train the model\n",
    "    epochs = 100           #Maximum number of epochs to run\n",
    "    batch_size = 32    #Size of training data batch\n",
    "    Val_split = 0.1       #Procentage of training data to use as validation data\n",
    "    history = self.model.fit(self.X_train, self.Y_train, epochs=epochs, batch_size=batch_size, validation_split=Val_split, callbacks=[es, tb, mc])\n",
    "    \n",
    "    # Save the model\n",
    "    filename = \"model_\" + name + \".hdf5\"\n",
    "    self.model.save_weights(weights_path + '/' + filename)\n",
    "    # Save the history\n",
    "    filename = \"history_\" + name + \".pickle\"\n",
    "    with open(train_history + '/' + filename, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "\n",
    "    set_up_data = setUpData\n",
    "    train_model = trainModel\n",
    "    \n",
    "    set_model_to_Basic_LSTM = setModelToBasicLSTM\n",
    "    set_model_to_Grid_Search = setModelToGridSearch\n",
    "    set_model_to_FFNN = setModelToFFNN\n",
    "    set_model_to_final_model = setModelToFinalModel\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test training FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32501, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-64192cdb3285>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mn_test_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.02\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpower_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_up_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseqLleng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoint_angle_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpower_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-a5fa9ca2f022>\u001b[0m in \u001b[0;36msetUpData\u001b[1;34m(self, seq_length, dataX, dataY, n_test_ratio, multiple)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseries_to_supervised\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn_test_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-57-5f1eda3bb90e>\u001b[0m in \u001b[0;36mseries_to_supervised\u001b[1;34m(dataX, dataY, n_input, n_output, multiple)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmultiple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gen = Generator()\n",
    "seqLleng = 2 #12ms/leng unit\n",
    "n_test_ratio = 0.02\n",
    "print((power_data.shape))\n",
    "gen.set_up_data(seqLleng, joint_angle_data, power_data, n_test_ratio, multiple=False)\n",
    "print(gen.X_train.shape)\n",
    "print(gen.Y_train.shape)\n",
    "print(gen.X_test.shape)\n",
    "print(gen.Y_test.shape)\n",
    "gen.set_model_to_FFNN()\n",
    "name = 'test_run_FFNN'\n",
    "gen.train_model(name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test training Basic LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32501, 1)\n",
      "(31826, 25, 19)\n",
      "(31826, 25, 1)\n",
      "(650, 25, 19)\n",
      "(650, 25, 1)\n",
      "Train on 28643 samples, validate on 3183 samples\n",
      "Epoch 1/100\n",
      "28643/28643 [==============================] - 28s 960us/step - loss: 57.1246 - mean_square_error: 9289620.2938 - val_loss: 45.8971 - val_mean_square_error: 5289680.2269\n",
      "Epoch 2/100\n",
      "28643/28643 [==============================] - 24s 832us/step - loss: 52.3628 - mean_square_error: 8836782.8509 - val_loss: 45.8719 - val_mean_square_error: 5304273.3516\n",
      "Epoch 3/100\n",
      "28643/28643 [==============================] - 24s 831us/step - loss: 52.3271 - mean_square_error: 8840184.6400 - val_loss: 45.7346 - val_mean_square_error: 5249623.9900\n",
      "Epoch 4/100\n",
      "28643/28643 [==============================] - 24s 838us/step - loss: 51.8281 - mean_square_error: 8726033.8992 - val_loss: 43.4154 - val_mean_square_error: 4821174.2676\n",
      "Epoch 5/100\n",
      "28643/28643 [==============================] - 24s 835us/step - loss: 31.4325 - mean_square_error: 3886298.0810 - val_loss: 18.4491 - val_mean_square_error: 996086.6352\n",
      "Epoch 6/100\n",
      "28643/28643 [==============================] - 24s 851us/step - loss: 12.5218 - mean_square_error: 625674.4345 - val_loss: 14.3822 - val_mean_square_error: 287118.1990\n",
      "Epoch 7/100\n",
      "28643/28643 [==============================] - 25s 856us/step - loss: 8.4966 - mean_square_error: 253210.0686 - val_loss: 11.4539 - val_mean_square_error: 190490.4963\n",
      "Epoch 8/100\n",
      "28643/28643 [==============================] - 24s 842us/step - loss: 6.9927 - mean_square_error: 158298.3996 - val_loss: 11.0057 - val_mean_square_error: 173702.4745\n",
      "Epoch 9/100\n",
      "28643/28643 [==============================] - 24s 850us/step - loss: 6.3008 - mean_square_error: 110869.9529 - val_loss: 11.4223 - val_mean_square_error: 193797.9763\n",
      "Epoch 10/100\n",
      "28643/28643 [==============================] - 24s 842us/step - loss: 6.0262 - mean_square_error: 93201.7124 - val_loss: 10.4639 - val_mean_square_error: 145096.1265\n",
      "Epoch 11/100\n",
      "28643/28643 [==============================] - 24s 845us/step - loss: 5.6266 - mean_square_error: 78100.0522 - val_loss: 9.6640 - val_mean_square_error: 121635.5587\n",
      "Epoch 12/100\n",
      "28643/28643 [==============================] - 24s 853us/step - loss: 5.4122 - mean_square_error: 67908.2094 - val_loss: 10.4896 - val_mean_square_error: 130309.1721\n",
      "Epoch 13/100\n",
      "28643/28643 [==============================] - 24s 848us/step - loss: 5.5154 - mean_square_error: 107651.1988 - val_loss: 10.0863 - val_mean_square_error: 128638.5527\n",
      "Epoch 14/100\n",
      "28643/28643 [==============================] - 24s 845us/step - loss: 4.9960 - mean_square_error: 57466.2546 - val_loss: 9.3706 - val_mean_square_error: 112906.6568\n",
      "Epoch 15/100\n",
      "28643/28643 [==============================] - 24s 847us/step - loss: 4.8636 - mean_square_error: 54642.2753 - val_loss: 9.8294 - val_mean_square_error: 118960.9641\n",
      "Epoch 16/100\n",
      "28643/28643 [==============================] - 24s 842us/step - loss: 4.8254 - mean_square_error: 53549.1494 - val_loss: 9.4789 - val_mean_square_error: 115580.1704\n",
      "Epoch 17/100\n",
      "28643/28643 [==============================] - 24s 850us/step - loss: 4.6367 - mean_square_error: 49983.2959 - val_loss: 9.1457 - val_mean_square_error: 113357.3116\n",
      "Epoch 18/100\n",
      "28643/28643 [==============================] - 24s 852us/step - loss: 4.5146 - mean_square_error: 47600.7420 - val_loss: 8.9662 - val_mean_square_error: 118266.0225\n",
      "Epoch 19/100\n",
      "28643/28643 [==============================] - 24s 852us/step - loss: 4.4972 - mean_square_error: 47841.8796 - val_loss: 9.3816 - val_mean_square_error: 114337.6898\n",
      "Epoch 20/100\n",
      "28643/28643 [==============================] - 24s 851us/step - loss: 4.3170 - mean_square_error: 44240.5329 - val_loss: 10.0982 - val_mean_square_error: 133051.6550\n",
      "Epoch 21/100\n",
      "28643/28643 [==============================] - 24s 855us/step - loss: 4.1961 - mean_square_error: 42235.5505 - val_loss: 9.7976 - val_mean_square_error: 130335.34840s - loss: 4.1988 - mean_squar\n",
      "Epoch 22/100\n",
      "28643/28643 [==============================] - 24s 849us/step - loss: 4.1133 - mean_square_error: 41426.0131 - val_loss: 9.3518 - val_mean_square_error: 120393.0320\n",
      "Epoch 23/100\n",
      "28643/28643 [==============================] - 24s 850us/step - loss: 4.0083 - mean_square_error: 39838.8390 - val_loss: 9.7986 - val_mean_square_error: 114284.4576\n"
     ]
    }
   ],
   "source": [
    "gen = Generator()\n",
    "seqLleng = 25 #12ms/leng unit\n",
    "n_test_ratio = 0.02\n",
    "multiple = True\n",
    "print((power_data.shape))\n",
    "gen.set_up_data(seqLleng, joint_angle_data, power_data, n_test_ratio, multiple=multiple)\n",
    "print(gen.X_train.shape)\n",
    "print(gen.Y_train.shape)\n",
    "print(gen.X_test.shape)\n",
    "print(gen.Y_test.shape)\n",
    "gen.set_model_to_Basic_LSTM(multiple=multiple)\n",
    "name = 'test_run_Basic_LSTM'\n",
    "gen.train_model(name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparamter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up data\n",
      "Creating keras Classifier\n",
      "Grid Search Starting\n",
      "X: (31849, 2, 19)\n",
      "Y: (31849, 1)\n",
      "Epoch 1/1\n",
      "21232/21232 [==============================] - 14s 644us/step - loss: 4976606.3505 - acc: 1.4130e-04\n",
      "10617/10617 [==============================] - 3s 244us/step\n",
      "21232/21232 [==============================] - 4s 175us/step\n",
      "Epoch 1/1\n",
      "21233/21233 [==============================] - 14s 649us/step - loss: 6445045.5566 - acc: 1.8839e-04\n",
      "10616/10616 [==============================] - 3s 268us/step\n",
      "21233/21233 [==============================] - 4s 166us/step\n",
      "Epoch 1/1\n",
      "21233/21233 [==============================] - 13s 628us/step - loss: 2088011.4116 - acc: 4.7097e-05\n",
      "10616/10616 [==============================] - 3s 276us/step\n",
      "21233/21233 [==============================] - 4s 196us/step\n",
      "Epoch 1/1\n",
      "21232/21232 [==============================] - 17s 809us/step - loss: 9336397.4477 - acc: 2.3549e-04\n",
      "10617/10617 [==============================] - 3s 311us/step\n",
      "21232/21232 [==============================] - 4s 207us/step\n",
      "Epoch 1/1\n",
      "21233/21233 [==============================] - 16s 763us/step - loss: 3116412.4297 - acc: 1.4129e-04\n",
      "10616/10616 [==============================] - 3s 312us/step\n",
      "21233/21233 [==============================] - 5s 230us/step\n",
      "Epoch 1/1\n",
      "21233/21233 [==============================] - 16s 776us/step - loss: 6367735.9204 - acc: 4.2387e-04\n",
      "10616/10616 [==============================] - 4s 338us/step\n",
      "21233/21233 [==============================] - 5s 217us/step\n",
      "Epoch 1/1\n",
      "21232/21232 [==============================] - 13s 621us/step - loss: 5842248.4485 - acc: 4.7099e-052s - loss: 4460\n",
      "10617/10617 [==============================] - 3s 283us/step\n",
      "21232/21232 [==============================] - 3s 147us/step\n",
      "Epoch 1/1\n",
      "21233/21233 [==============================] - 14s 647us/step - loss: 7618615.7404 - acc: 2.3548e-04\n",
      "10616/10616 [==============================] - 3s 282us/step\n",
      "21233/21233 [==============================] - 3s 156us/step\n",
      "Epoch 1/1\n",
      "21233/21233 [==============================] - 14s 675us/step - loss: 4959617.2442 - acc: 3.2968e-04\n",
      "10616/10616 [==============================] - 3s 301us/step\n",
      "21233/21233 [==============================] - 3s 158us/step\n",
      "Epoch 1/1\n",
      "21232/21232 [==============================] - 17s 790us/step - loss: 8381845.5505 - acc: 1.8839e-04\n",
      "10617/10617 [==============================] - 3s 324us/step\n",
      "21232/21232 [==============================] - 4s 177us/step\n",
      "Epoch 1/1\n",
      "21233/21233 [==============================] - 16s 752us/step - loss: 6280418.2217 - acc: 4.7097e-05\n",
      "10616/10616 [==============================] - 4s 337us/step\n",
      "21233/21233 [==============================] - 4s 183us/step\n",
      "Epoch 1/1\n",
      "21233/21233 [==============================] - 16s 772us/step - loss: 1572242.7615 - acc: 1.4129e-04\n",
      "10616/10616 [==============================] - 4s 347us/step\n",
      "21233/21233 [==============================] - 4s 186us/step\n",
      "Epoch 1/1\n",
      "31849/31849 [==============================] - 26s 821us/step - loss: 2581111.4708 - acc: 1.5699e-04\n"
     ]
    }
   ],
   "source": [
    "gen_gs = Generator()\n",
    "# Variables\n",
    "seqLength = 2 #12ms/leng unit\n",
    "n_test_ratio = 0.02\n",
    "multiple = False\n",
    "# Set up the data\n",
    "print('Setting up data')\n",
    "gen_gs.set_up_data(seqLength, joint_angle_data, power_data, n_test_ratio, multiple=multiple)\n",
    "# create model\n",
    "print('Creating keras Classifier')\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "model = KerasClassifier(build_fn=gen_gs.set_model_to_Grid_Search, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "# define the grid search parameters\n",
    "multiple = [multiple]\n",
    "layer_type = [CuDNNLSTM, CuDNNGRU]\n",
    "hidden_units_RNN = [64, 128]\n",
    "hidden_units_dense = [64, 128]\n",
    "num_dense_layers = [1, 2]\n",
    "num_mid_layers = [0, 2, 4]\n",
    "#optimizer = ['adam']\n",
    "#learn_rate = [0.01]\n",
    "#momentum = [0]\n",
    "#init_mode = ['random_uniform']\n",
    "#activation = ['relu']\n",
    "dropout_rate = [0, 0.2, 0,4]\n",
    "#weight_constraint = [0]\n",
    "# Make dictionary\n",
    "param_grid = dict(multiple=multiple,\n",
    "                  layer_type=layer_type,\n",
    "                  hidden_units_dense=hidden_units_dense,\n",
    "                  hidden_units_RNN=hidden_units_RNN,\n",
    "                  num_mid_layers=num_mid_layers,\n",
    "                  dropout_rate=dropout_rate,\n",
    "                  num_dense_layers=num_dense_layers)\n",
    "# Grid Search\n",
    "print('Grid Search Starting')\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "print('X: ' + str(gen_gs.X_train.shape))\n",
    "print('Y: ' + str(gen_gs.Y_train.shape))\n",
    "grid_result = grid.fit(gen_gs.X_train, gen_gs.Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.000314 using {'dropout_rate': 0.2, 'hidden_units_RNN': 128, 'hidden_units_dense': 128, 'layer_type': <class 'keras.layers.cudnn_recurrent.CuDNNLSTM'>, 'multiple': False, 'num_dense_layers': 1, 'num_mid_layers': 2}\n",
      "0.000157 (0.000222) with: {'dropout_rate': 0.2, 'hidden_units_RNN': 128, 'hidden_units_dense': 128, 'layer_type': <class 'keras.layers.cudnn_recurrent.CuDNNLSTM'>, 'multiple': False, 'num_dense_layers': 1, 'num_mid_layers': 1}\n",
      "0.000314 (0.000222) with: {'dropout_rate': 0.2, 'hidden_units_RNN': 128, 'hidden_units_dense': 128, 'layer_type': <class 'keras.layers.cudnn_recurrent.CuDNNLSTM'>, 'multiple': False, 'num_dense_layers': 1, 'num_mid_layers': 2}\n",
      "0.000157 (0.000222) with: {'dropout_rate': 0.2, 'hidden_units_RNN': 128, 'hidden_units_dense': 128, 'layer_type': <class 'keras.layers.cudnn_recurrent.CuDNNGRU'>, 'multiple': False, 'num_dense_layers': 1, 'num_mid_layers': 1}\n",
      "0.000157 (0.000222) with: {'dropout_rate': 0.2, 'hidden_units_RNN': 128, 'hidden_units_dense': 128, 'layer_type': <class 'keras.layers.cudnn_recurrent.CuDNNGRU'>, 'multiple': False, 'num_dense_layers': 1, 'num_mid_layers': 2}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results from the Grid Search\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Saving\n"
     ]
    }
   ],
   "source": [
    "mylist = [['mean_test_score', 'std_test_score', 'params']]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    mylist.append([mean, stdev, param])\n",
    "    \n",
    "with open('Grid_Search_Result.csv', 'w') as myfile:\n",
    "    #wr = csv.writer(myfile, dialect='excel')\n",
    "    for row in mylist:\n",
    "        for column in row:\n",
    "            myfile.write('%s;' % column)\n",
    "        myfile.write('\\n')\n",
    "    myfile.close()\n",
    "print('Done Saving')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction using train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = gen.model.predict(gen.X_train)\n",
    "predictions_test = gen.model.predict(gen.X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = [100:1000]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "fig1 = plt.subplot()\n",
    "x1 = range(len(predictions_train))\n",
    "fig1.plot(x1[time_interval], gen.Y_train[time_interval],  label='true',  marker='o',linewidth=0.3, markersize=4)\n",
    "fig1.plot(x1[time_interval], predictions_train[time_interval],  label='pred',  marker='o',linewidth=0.3, markersize=4)\n",
    "fig1.legend();\n",
    "fig1.set_ylabel('Power[W]')\n",
    "fig1.set_xlabel('Time')\n",
    "fig1.set_title('Train data prediction');\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "fig2 = plt.subplot()\n",
    "x2 = range(len(predictions_test))\n",
    "fig2.plot(x2, gen.Y_test,  label='true',  marker='o',linewidth=0.3, markersize=4)\n",
    "fig2.plot(x2, predictions_test,  label='pred',  marker='o',linewidth=0.3, markersize=4)\n",
    "fig2.legend();\n",
    "fig2.set_ylabel('Power[W]')\n",
    "fig2.set_xlabel('Time')\n",
    "fig2.set_title('Test data prediction');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for final training\n",
    "path_to_data_mapp = 'Pickled_data'\n",
    "gen_final = Generator()\n",
    "seqLleng = 25 #12ms/leng unit\n",
    "n_test_ratio = 0\n",
    "num_of_test_paths = 1\n",
    "gen_final.set_model_to_final_model()\n",
    "\n",
    "joint_angle_data_path_list = []\n",
    "power_data_path_list = []\n",
    "\n",
    "for name in os.listdir(folder_path):\n",
    "    path = os.path.join(folder_path, name)\n",
    "    if \"_auginput.pickle\" in name:\n",
    "        joint_angle_data_path_list.append(name)\n",
    "    if \"_poweroutput.pickle\" in name:\n",
    "        power_data_path_list.append(name)\n",
    "\n",
    "match_list_vector = []\n",
    "for filename in joint_angle_data_path_list:\n",
    "    name = filename[:-len(\"_auginput.pickle\")]\n",
    "    num = 0\n",
    "    for filename in power_data_path_list:\n",
    "        if name in filename:\n",
    "            match_list_vector.append(num)\n",
    "            continue\n",
    "        num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training\n",
    "for n in range(len(joint_angle_data_path_list)-num_of_test_paths):\n",
    "    #joint_angle_data.pickle\n",
    "    with open(path_to_data_mapp + joint_angle_data_path_list(n), 'rb') as file:\n",
    "        joint_angle_data = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "    #power_data.pickle\n",
    "    with open(path_to_data_mapp + power_data_path_list(match_list_vector(n)), 'rb') as file:\n",
    "        power_data = pickle.load(file)\n",
    "        file.close()\n",
    "    \n",
    "    gen_final.set_up_data(seqLleng, joint_angle_data, power_data, n_test_ratio)\n",
    "    name = 'Final_Model'\n",
    "    gen_final.train_model(name = name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Resulting figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = gen.model.predict(gen.X_test)\n",
    "time_interval = [100:1000]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "fig = plt.subplot()\n",
    "x = range(len(predictions_test))\n",
    "fig.plot(x[time_interval], gen.Y_test[time_interval],  label='true',  marker='o',linewidth=0.3, markersize=4)\n",
    "fig.plot(x[time_interval], predictions_test[time_interval],  label='pred',  marker='o',linewidth=0.3, markersize=4)\n",
    "fig.legend();\n",
    "fig.set_ylabel('Power [W]')\n",
    "fig.set_xlabel('Time [s]')\n",
    "fig.set_title('Test data prediction');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
