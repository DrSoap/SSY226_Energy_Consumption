{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Multiple Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import zipfile\n",
    "import pickle\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "import scipy.signal as sg\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open joint angle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_angle_data(a_data):\n",
    "    with open(a_data, 'r') as file:\n",
    "        try:\n",
    "            data = file.read()\n",
    "            file.close()\n",
    "        except UnicodeDecodeError:\n",
    "            file.close()\n",
    "    data = data.splitlines()\n",
    "    data = data[4:len(data)-1] #Text information on first four rows and END on last row\n",
    "\n",
    "    data_dim = len(data[0].split()[1:])\n",
    "\n",
    "    traj_data = np.ndarray((len(data),data_dim))\n",
    "    for i, row in enumerate(data):\n",
    "        traj_data[i] = np.array([float(n)*np.pi/180 for n in row.split()[1:]])\n",
    "    \n",
    "    return traj_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open voltage and current data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_power_data(p_data):\n",
    "    f = open(p_data)\n",
    "\n",
    "    data = []\n",
    "    for line in f:\n",
    "        data_line = line.rstrip().split('\\t')\n",
    "        data.append(data_line)\n",
    "\n",
    "    init=True\n",
    "    for i, file in enumerate(data[9:]):\n",
    "        file = file[0].replace(',','.')\n",
    "        file = file.replace(' ','')\n",
    "        if init:\n",
    "            Volt_Amp_data = np.ndarray((len(data),len(file.split(';'))-1))\n",
    "            init=False\n",
    "        Volt_Amp_data[i] = np.array([float(n) for n in file.split(';')[:len(file.split(';'))-1]])\n",
    "   \n",
    "    return Volt_Amp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_temp_data(temp_data_path):\n",
    "    temp = pd.read_excel(temp_data_path)\n",
    "    temp = temp.values\n",
    "    temp_data = temp[0][3:]\n",
    "    \n",
    "    return temp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate temerature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_temp(temp_data,traj_data_synced):\n",
    "    n_timesteps = len(traj_data_synced)\n",
    "    num_joints=6\n",
    "    temp_lin_int = np.ndarray((n_timesteps,num_joints))\n",
    "    for i in range(num_joints):\n",
    "        temp_lin_int[0:,i] = np.linspace(temp_data[0+i],temp_data[6+i],num=n_timesteps)\n",
    "    return temp_lin_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate momentaneous power form voltage/current measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_moment_power(Volt_Amp_data):\n",
    "    n_phases   = 3   #Number of phases in measured data\n",
    "    power_data = np.ndarray((len(Volt_Amp_data),1))\n",
    "    amp_data   = np.ndarray((len(Volt_Amp_data),n_phases))\n",
    "    volt_data  = np.ndarray((len(Volt_Amp_data),n_phases))\n",
    "\n",
    "    for i, sample in enumerate(Volt_Amp_data):\n",
    "        volt_data[i]  = np.array([sample[1], sample[2], sample[3]])\n",
    "        amp_data[i]   = np.array([sample[4], sample[5], sample[6]])\n",
    "        power_data[i] = np.abs(sample[1]*sample[4]) \\\n",
    "            + np.abs(sample[2]*sample[5]) \\\n",
    "            + np.abs(sample[3]*sample[6]) \n",
    "    \n",
    "    return power_data, volt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate moving average of momentaneous power. Moving average is calculated for one period at a time so that the current spikes behaves similarly in every calculated average. Then the average is upsampled with a factor of 5 (from 50Hz to 250 Hz) because this is an even factor of 3 times the sample frequency of the angle measurements which will be upsampled to to the same frequency later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Downsample_powerdata(volt_data, power_data):\n",
    "    period    = 200\n",
    "    power_data_250 = np.ndarray((len(range(period,len(volt_data),period))*5,1))\n",
    "    start = np.argmin(volt_data[0:200])\n",
    "\n",
    "    i=0\n",
    "    for j in range(start,len(power_data),period):\n",
    "        power_data_250[i:i+5] = np.mean(power_data[j:j+period])\n",
    "        i += 5\n",
    "\n",
    "    #Linear interpolation instead of constant value upsampling\n",
    "    i=0\n",
    "    lin_in=np.ndarray((5,1))\n",
    "    for j in range(0,len(power_data_250),5):\n",
    "        a = power_data_250[i]\n",
    "        if i+6 > len(power_data_250):\n",
    "            break\n",
    "        b = power_data_250[i+6]\n",
    "        lin_in = np.linspace(a,b,num=5).reshape(5,1)\n",
    "        power_data_250[i:i+5] = lin_in\n",
    "        i+=5\n",
    "    \n",
    "    return power_data_250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate velocity, acceleration and pseudopower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vel_acc_psi(traj_data):\n",
    "    #Time vector for angle measurements (fixed in KUKA system)\n",
    "    delta_t = 0.012\n",
    "    t = np.ndarray((len(traj_data),1))\n",
    "    t[0] = 0\n",
    "    for i in range(1,len(traj_data)):\n",
    "        t[i] = t[i-1] + delta_t\n",
    "\n",
    "    #Velocity \n",
    "    vel = np.ndarray(np.shape(traj_data))\n",
    "    for i in range(len(traj_data)-1):\n",
    "        vel[i] = np.divide( traj_data[i+1] - traj_data[i], delta_t)\n",
    "    vel[-1] = vel[-2]\n",
    "\n",
    "    #Acceleration\n",
    "    acc = np.ndarray(np.shape(traj_data))\n",
    "    for i in range(len(traj_data)-1):\n",
    "        acc[i] = np.divide( vel[i+1] - vel[i], delta_t)\n",
    "    acc[-1] = acc[-2]\n",
    "\n",
    "    #Pseudopower\n",
    "    psi = np.ndarray((np.shape(traj_data)[0],1))\n",
    "    for i in range(len(traj_data)):\n",
    "        psi[i] = np.sum(np.abs(vel[i]*acc[i]))\n",
    "        \n",
    "    return vel, acc, psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsample angle measurement data to 250 Hz using linear interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Upsample_ang_vel_acc_psi(traj_data,vel,acc,psi):\n",
    "    US = 3 #Upsample factor\n",
    "    traj_data_us = np.ndarray((len(traj_data)*US,6))\n",
    "    vel_us = np.ndarray(np.shape(traj_data_us))\n",
    "    acc_us = np.ndarray(np.shape(traj_data_us))\n",
    "    psi_us = np.ndarray((len(traj_data)*US,1))\n",
    "    k=0\n",
    "    for i, angles in enumerate(traj_data[0:-1]):\n",
    "        for j in range(len(angles)):\n",
    "            a = traj_data[i][j]\n",
    "            b = traj_data[i+1][j]\n",
    "            lin_in = np.linspace(a,b,num=US)\n",
    "            traj_data_us[k:k+US,j] = lin_in\n",
    "\n",
    "            a = vel[i][j]\n",
    "            b = vel[i+1][j]\n",
    "            lin_in = np.linspace(a,b,num=US)\n",
    "            vel_us[k:k+US,j] = lin_in\n",
    "\n",
    "            a = acc[i][j]\n",
    "            b = acc[i+1][j]\n",
    "            lin_in = np.linspace(a,b,num=US)\n",
    "            acc_us[k:k+US,j] = lin_in\n",
    "\n",
    "        a = psi[i]\n",
    "        b = psi[i+1]\n",
    "        lin_in = np.linspace(a,b,num=US).reshape(US,1)\n",
    "        psi_us[k:k+US] = lin_in\n",
    "\n",
    "        k+=US\n",
    "        \n",
    "    return traj_data_us, vel_us, acc_us, psi_us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find start of power- and angle measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_starts(power_data_250, traj_data_us, acc_us):\n",
    "    Start_power_indicator = 300\n",
    "    for i in range(len(power_data_250)):\n",
    "        if power_data_250[i+10]-power_data_250[i]>Start_power_indicator:\n",
    "            starting_point_power = i\n",
    "            break\n",
    "    #print('Start at power sample:',starting_point_power-1,' corresponding to time:',power_time_ds[starting_point_power-1],'sec')\n",
    "\n",
    "    Start_trajectory_indicator = 0.5\n",
    "    for i in range(len(traj_data_us)):\n",
    "        if np.max(np.abs(acc_us[i+10]))>Start_trajectory_indicator:\n",
    "            starting_point_traj = i\n",
    "            break\n",
    "    #print('Start at trajectory sample:',starting_point_traj,' corresponding to time:',t[starting_point_traj],'sec')\n",
    "    return starting_point_power, starting_point_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_data(traj_data_us,vel_us,acc_us,psi_us,starting_point_traj,power_data_250,starting_point_power):\n",
    "    #Align the data\n",
    "    traj_data_synced = traj_data_us[starting_point_traj:-1]\n",
    "    vel_synced = vel_us[starting_point_traj:-1]\n",
    "    acc_synced = acc_us[starting_point_traj:-1]\n",
    "    psi_synced = psi_us[starting_point_traj:-1]\n",
    "    power_data_synced = power_data_250[starting_point_power-1:starting_point_power-1+len(traj_data_synced)]\n",
    "    return traj_data_synced, vel_synced, acc_synced, psi_synced, power_data_synced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the input vector and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aug_input(traj_data_synced, vel_synced, acc_synced, psi_synced, power_data_synced, temp_data):\n",
    "    #Create the augmented input vector containing [angle1,..,angle6, vel1,..,vel6, acc1,..,acc6, psi] for all timesteps.\n",
    "    aug_feature_dim = 25\n",
    "    aug_input = np.ndarray((len(traj_data_synced),aug_feature_dim))\n",
    "\n",
    "    for i in range(len(traj_data_synced)):\n",
    "        aug_input[i] = np.concatenate((traj_data_synced[i], vel_synced[i], acc_synced[i], psi_synced[i], temp_data[i]), axis=None)\n",
    "\n",
    "    return aug_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize input data within axis range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_inputs(traj_data_synced, vel_synced, acc_synced, psi_synced, power_data_synced, temp_data):\n",
    "    feature_dim = len(traj_data_synced[0])*4 + 1\n",
    "\n",
    "    aug_input_norm = np.ndarray((len(traj_data_synced),feature_dim))\n",
    "    traj_data_norm = np.ndarray(np.shape(traj_data_synced))\n",
    "    vel_norm = np.ndarray(np.shape(vel_synced))\n",
    "    acc_norm = np.ndarray(np.shape(acc_synced))\n",
    "    psi_norm = np.ndarray(np.shape(psi_synced))\n",
    "    temp_norm = np.ndarray(np.shape(temp_data))\n",
    "        \n",
    "    A1_constraint = [np.deg2rad(-185), np.deg2rad(185)]\n",
    "    A2_constraint = [np.deg2rad(-135), np.deg2rad(35)]\n",
    "    A3_constraint = [np.deg2rad(-120), np.deg2rad(158)]\n",
    "    A4_constraint = [np.deg2rad(-350), np.deg2rad(350)]\n",
    "    A5_constraint = [np.deg2rad(-119), np.deg2rad(119)]\n",
    "    A6_constraint = [np.deg2rad(-350), np.deg2rad(350)]\n",
    "\n",
    "    vel_max = 4.159647569601188\n",
    "    vel_min = -3.9450433392170803\n",
    "    acc_max = 27.338764681179683\n",
    "    acc_min = -28.319179147808107\n",
    "    psi_max = 126.43383111466377\n",
    "    psi_min = 0.0\n",
    "    temp_max = 340\n",
    "    temp_min = 285\n",
    "\n",
    "    constraints_min = [A1_constraint[0],A2_constraint[0],A3_constraint[0],A4_constraint[0],A5_constraint[0],A6_constraint[0]]\n",
    "    constraints_diff = [float(np.diff(A1_constraint)), float(np.diff(A2_constraint)),float(np.diff(A3_constraint)),float(np.diff(A4_constraint)),float(np.diff(A5_constraint)),float(np.diff(A6_constraint))]\n",
    "\n",
    "    vel_diff = vel_max - vel_min\n",
    "    acc_diff = acc_max - acc_min\n",
    "    psi_diff = psi_max - psi_min\n",
    "    temp_diff = temp_max - temp_min\n",
    "\n",
    "    for i in range(len(traj_data_synced)):\n",
    "        traj_data_norm[i] = 2*np.divide((traj_data_synced[i] - constraints_min),constraints_diff) - 1\n",
    "        vel_norm[i] = 2*(vel_synced[i] - vel_min)/vel_diff - 1\n",
    "        acc_norm[i] = 2*(acc_synced[i] - acc_min)/acc_diff - 1\n",
    "        psi_norm[i] = psi_synced[i]/psi_diff    \n",
    "        temp_norm[i] = 2*(temp_data[i] - temp_min)/temp_diff - 1\n",
    "        aug_input_norm[i] = np.concatenate((traj_data_norm[i], vel_norm[i], acc_norm[i], psi_norm[i], temp_norm[i]), axis=None)\n",
    "        \n",
    "    return aug_input_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(aug_input,name_aug,aug_input_norm,name_norm,power_data_synced,name_power):\n",
    "    with open(name_aug, 'wb') as file:\n",
    "        pickle.dump(aug_input, file)\n",
    "        file.close()\n",
    "\n",
    "    with open(name_norm, 'wb') as file:\n",
    "        pickle.dump(aug_input_norm, file)\n",
    "        file.close()\n",
    "\n",
    "    with open(name_power, 'wb') as file:\n",
    "        pickle.dump(power_data_synced, file)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through all data files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_data():\n",
    "    \n",
    "    angle_datapath = 'Collected data/AxisData/'\n",
    "    power_datapath = 'Collected data/PowerData/'\n",
    "    temp_datapath = 'Collected data/TempData/'\n",
    "    \n",
    "    angle_files = [f for f in listdir(angle_datapath) if isfile(join(angle_datapath, f))]\n",
    "    power_files = [f for f in listdir(power_datapath) if isfile(join(power_datapath, f))]\n",
    "    temp_files = [f for f in listdir(temp_datapath) if isfile(join(temp_datapath, f))]\n",
    "    \n",
    "    \n",
    "    for i in range(len(power_files)):\n",
    "        print('Processing angle file: ' + angle_files[i])\n",
    "        print('Processing power file: ' + power_files[i])\n",
    "        print('Processing temperature file: ' + temp_files[i])\n",
    "        print('')\n",
    "        a_data = angle_datapath + angle_files[i] #The angle data\n",
    "        p_data = power_datapath + power_files[i] #The power data\n",
    "        temp_data_path = temp_datapath + temp_files[i] #Temperature data\n",
    "        \n",
    "        traj_data = open_angle_data(a_data)\n",
    "        vel, acc, psi = calc_vel_acc_psi(traj_data)\n",
    "        traj_data_us, vel_us, acc_us, psi_us = Upsample_ang_vel_acc_psi(traj_data,vel,acc,psi)\n",
    "        \n",
    "        Volt_Amp_data = open_power_data(p_data)\n",
    "        power_data, volt_data = calc_moment_power(Volt_Amp_data)\n",
    "        power_data_250 = Downsample_powerdata(volt_data, power_data)\n",
    "        \n",
    "        starting_point_power, starting_point_traj = find_starts(power_data_250, traj_data_us, acc_us)\n",
    "        traj_data_synced, vel_synced, acc_synced, psi_synced, power_data_synced = align_data(traj_data_us,vel_us,acc_us,psi_us,starting_point_traj,power_data_250,starting_point_power)\n",
    "        temp_data = open_temp_data(temp_data_path)\n",
    "        temp_lin_int = interpolate_temp(temp_data,traj_data_synced)\n",
    "        \n",
    "        aug_input = create_aug_input(traj_data_synced, vel_synced, acc_synced, psi_synced, power_data_synced,temp_lin_int)\n",
    "        aug_input_norm = normalize_inputs(traj_data_synced, vel_synced, acc_synced, psi_synced, power_data_synced,temp_lin_int)\n",
    "        \n",
    "        if not os.path.isdir('Pickled_data'):\n",
    "            os.mkdir('Pickled_data')\n",
    "        \n",
    "        pickled_datapath = 'Pickled_data'\n",
    "        path_aug = pickled_datapath + '/' + angle_files[i].replace('.txt','') + '_auginput.pickle'\n",
    "        path_norm = pickled_datapath + '/'+angle_files[i].replace('.txt','') + '_augnorminput.pickle'\n",
    "        path_power = pickled_datapath + '/'+angle_files[i].replace('.txt','') + '_poweroutput.pickle'\n",
    "        save_data(aug_input,path_aug,aug_input_norm,path_norm,power_data_synced,path_power)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now everything is defined, time to process all data files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
